{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "class VAE:\n",
    "    def __init__(self, training_data, validation_data, use_multiprocessing=False, workers=1, verbose=1,\n",
    "                 inter_dim=512, latent_dim=2, batch_size=128, epochs=10, beta=1, plot_models=True):\n",
    "\n",
    "        # self.training_generator = training_generator\n",
    "        # self.validation_generator = validation_generator\n",
    "        #\n",
    "        # self.input_shape = training_generator.dim\n",
    "        self.input_shape = training_data.shape[1]\n",
    "        self.beta = beta\n",
    "        self.num_epochs = epochs\n",
    "        self.use_multiprocessing = use_multiprocessing\n",
    "        self.workers = workers\n",
    "        self.verbose = verbose\n",
    "\n",
    "        input_encoder = Input(shape=(self.input_shape,), name='encoder_input')\n",
    "        z_mean, z_log_var, z = self.encoder_net(input_encoder, inter_dim, latent_dim)\n",
    "        encoder = Model(input_encoder, [z_mean, z_log_var, z], name='encoder')\n",
    "        print(encoder.summary())\n",
    "        if plot_models is True:\n",
    "            plot_model(encoder, to_file='my_encoder.png', show_shapes=True)\n",
    "\n",
    "        input_decoder = Input(shape=(latent_dim,), name='decoder_input')\n",
    "        output_decoder = self.decoder_net(input_decoder, inter_dim, self.input_shape)\n",
    "        decoder = Model(input_decoder, output_decoder, name='decoder')\n",
    "        print(decoder.summary())\n",
    "        if plot_models is True:\n",
    "            plot_model(decoder, to_file='my_decoder.png', show_shapes=True)\n",
    "\n",
    "        vae_output = decoder(encoder(input_encoder)[2])\n",
    "        vae = Model(input_encoder, vae_output, name='vae')\n",
    "\n",
    "        vae_loss = K.mean(self.reconstructuion_loss(input_encoder, vae_output) + self.KL_loss(z_mean, z_log_var))\n",
    "        vae.add_loss(vae_loss)\n",
    "\n",
    "        vae.compile(optimizer='adam')\n",
    "        if plot_models is True:\n",
    "            plot_model(vae, to_file='my_vae.png', show_shapes=True)\n",
    "\n",
    "        # history = vae.fit_generator(generator=self.training_generator, validation_data=self.validation_generator,\n",
    "        #                               use_multiprocessing=self.use_multiprocessing, workers=self.workers,\n",
    "        #                               verbose=self.verbose, epochs=self.num_epochs, shuffle=True)\n",
    "        history = vae.fit(training_data, epochs=epochs, batch_size=batch_size,\n",
    "                          validation_data=(validation_data, None))\n",
    "\n",
    "        self.vae = vae\n",
    "        self.history = history\n",
    "        self.models = (encoder, decoder)\n",
    "\n",
    "    @staticmethod\n",
    "    def reconstructuion_loss(inputs, outputs):\n",
    "        reconstruction_loss = mse(inputs, outputs)\n",
    "        reconstruction_loss *= original_dim\n",
    "        return reconstruction_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def KL_loss(z_mu, log_z_variance):\n",
    "        kl_loss = 1 + log_z_variance - K.square(z_mu) - K.exp(log_z_variance)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "        return kl_loss\n",
    "\n",
    "\n",
    "    def sampling(self, args):\n",
    "        \"\"\"\n",
    "        Instead of sampling from Q(z|X), sample epsilon = N(0,I),\n",
    "        then  z = z_mean + sqrt(var) * epsilon\n",
    "        \"\"\"\n",
    "        z_mu, z_log_var = args\n",
    "\n",
    "        batch = K.shape(z_mu)[0]\n",
    "        dim = K.int_shape(z_mu)[1]\n",
    "\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mu + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    def encoder_net(self, inputs, intermediate_dim, latent_dim):\n",
    "        x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "        z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "        z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "        z = Lambda(self.sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z\n",
    "\n",
    "    def decoder_net(self, latent_inputs, intermediate_dimensions, input_dimensions):\n",
    "        y = Dense(intermediate_dimensions, activation='relu')(latent_inputs)\n",
    "        outputs = Dense(input_dimensions, activation='sigmoid')(y)\n",
    "        return outputs\n",
    "\n",
    "    def predict_latent_mean_std(self, testing_data):\n",
    "        encoder = self.models[0]\n",
    "        z_mean, z_var, z = encoder.predict(testing_data)\n",
    "        return z_mean, np.exp(0.5 * z_var)\n",
    "\n",
    "    def generate_new_image(self, testing_data):\n",
    "        new_image = self.vae.predict(testing_data)\n",
    "        return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "original_dim = image_size * image_size\n",
    "x_train = np.reshape(x_train, [-1, original_dim])\n",
    "x_test = np.reshape(x_test, [-1, original_dim])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "model = VAE(x_train, x_test[:10], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_training = model.vae.predict(x_train)\n",
    "predicted_training = predicted_training.reshape(len(x_train), 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = model.vae.predict(x_test)\n",
    "predicted_test = predicted_test.reshape(len(x_test), 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = plt.imshow(predicted_training[1048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = x_train.reshape(60000, 28, 28)\n",
    "f1 = plt.imshow(x_train2[1048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}